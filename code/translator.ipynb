{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmkAKRJzQJRZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmOr72Kn8XAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcacfc07-9b41-499a-fc15-8160f1e269f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fIDDYrn1u1mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-1-usV3iOhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses\n",
        "!pip install subword_nmt\n",
        "!pip install indicnlp\n",
        "!pip install indic_nlp_library\n",
        "!pip install mosestokenizer\n",
        "!pip install inference\n",
        "!pip install fairseq\n",
        "import sacremoses\n",
        "from indicnlp import tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333c3a3a-b678-41fb-a06e-ed34e646b028",
        "id": "VqpmPNxOiPJV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=cc9c1ff88eaa8389fb94353b95c3b0142d4868cdea28fa5f8c876e4ecd9ad661\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting subword_nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword_nmt) (4.64.1)\n",
            "Installing collected packages: mock, subword-nmt\n",
            "Successfully installed mock-4.0.3 subword-nmt-0.3.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indicnlp\n",
            "  Downloading indicnlp-0.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: indicnlp\n",
            "Successfully installed indicnlp-0.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic_nlp_library\n",
            "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.1.1-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 9.4 MB/s \n",
            "\u001b[?25hCollecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic_nlp_library) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from indic_nlp_library) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic_nlp_library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic_nlp_library) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->indic_nlp_library) (1.15.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->indic_nlp_library) (1.8.6)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (21.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (57.4.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (0.7.12)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (0.17.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.6.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.11.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.2.4)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.23.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (3.0.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.1.5)\n",
            "Installing collected packages: sphinx-rtd-theme, sphinx-argparse, morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.81 morfessor-2.0.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mosestokenizer\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting openfile\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "Collecting toolwrapper\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "Building wheels for collected packages: mosestokenizer, docopt, toolwrapper, uctools\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49210 sha256=8e81a0f16b66a93c8b39896c3c45295288f1e1aee0c6ba0354b5f66d996b4743\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/35/f7/af1258779a0b890abc3c79481460c597cb1f3659d0603cfb9d\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=79b19b44c78864f1eb6eb3b32ec246d5b46fec85c5d3bf43f9b897f6751fb1b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3378 sha256=4e34d5436a1095bb716a8b9ca25cafe06aeba081b08edbd4a4541d63adaed95a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/4f/33/54741ffe08e38ececb1d28068a153729b4fe820bafa0a0691f\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6185 sha256=9878776f030578847eedfbe3cb1266e9fc4e035723c705cc966ee02fef492a22\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/44/e9/914cf8fa71f0141f9314f862538d1218fcf2b94542a0fb7d35\n",
            "Successfully built mosestokenizer docopt toolwrapper uctools\n",
            "Installing collected packages: uctools, toolwrapper, openfile, docopt, mosestokenizer\n",
            "Successfully installed docopt-0.6.2 mosestokenizer-1.2.1 openfile-0.0.7 toolwrapper-2.1.0 uctools-1.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting inference\n",
            "  Downloading inference-0.1.tar.gz (591 bytes)\n",
            "Building wheels for collected packages: inference\n",
            "  Building wheel for inference (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inference: filename=inference-0.1-py3-none-any.whl size=992 sha256=c6eea3778c5171a2a3639392e4f52b9a0ade96b6c09d207a1da07418d3e19f06\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b0/30/9962866a3c844da687cef5b0b40a3a3753824ce7cfa05d7f15\n",
            "Successfully built inference\n",
            "Installing collected packages: inference\n",
            "Successfully installed inference-0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.64.1)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 61.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.12.1+cu113)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.21.6)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2022.6.2)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.12.1+cu113)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.10.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.10.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=deac4b7d0af3a7ee291ca01cb2da05fca927410be010c6680b94c98b9cecc158\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.6.0 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.6.0 sacrebleu-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8AfFlXy8J3o",
        "outputId": "cfde0e3b-ee8f-4dc2-88df-096b99de6baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2022.6.2)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.12.1+cu113)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.21.6)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.3.1)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.6.0)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.10.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/My Drive/translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50oKIhlhgkKz",
        "outputId": "c983df3a-84b2-4ad0-ab66-4233cd317c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/translate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import model_configs"
      ],
      "metadata": {
        "id": "y11YE6wH-lco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd indic-en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifr7e8EPk-Af",
        "outputId": "0dcd9690-724f-4132-9759-94e5ad039cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/translate/indic-en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from indicTrans.inference.engine import Model\n",
        "\n",
        "import indicTrans\n",
        "import indicTrans.inference\n",
        "from indicTrans import indic_nlp_library, inference\n",
        "import fairseq\n",
        "from inference.engine import Model\n",
        "#from inference import engine\n",
        "#indic2en_model = Model(expdir='../indic-en')\n"
      ],
      "metadata": {
        "id": "BGgsGK0sfPWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indic2en_model = Model(expdir='/content/gdrive/MyDrive/translate/indic-en') #run cell twice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gluvq3ehfhHQ",
        "outputId": "bb0afaca-6600-405e-bc7e-75f1b36256a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing vocab and bpe\n",
            "Initializing model for translation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cd indicTrans"
      ],
      "metadata": {
        "id": "yBfPAgL4rSQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cd .."
      ],
      "metadata": {
        "id": "X5lQVOBGIy6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cd /content/gdrive/MyDrive/translate/indic-en"
      ],
      "metadata": {
        "id": "zkqPfQSHMLii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#help(indic2en_model)"
      ],
      "metadata": {
        "id": "bwvuoD-jAG0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "azdGSOMDAzrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/img data/tweets-train_012_punc.csv', sep=',')\n",
        "#df = pd.read_csv('/content/tweets-train_pp_img_tweets_punctuation_quotes.csv', sep=',')"
      ],
      "metadata": {
        "id": "6YGQ5pZ2Ay2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "l3nmveWYNi3w",
        "outputId": "efaa099e-7096-4849-8319-8e9bc0a592cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ज्येष्ठ पत्रकार अनंत दीक्षित यांच्या निधनाचे वृत्त दुखद आहे. चार दशकं त्यांनी आपल्या परखड लेखणीने पत्रकारितेत अमूल्य योगदान दिले. दीक्षित यांच्या मार्गदर्शनाखाली पत्रकारांची पिढी घडली. अनंत दीक्षित यांना भावपूर्ण श्रद्धांजली आम्ही त्यांच्या परिवाराच्या दुखात सहभागी आहोत.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text = df['tweet'][0].to_list()\n",
        "#text = ['ज्येष्ठ पत्रकार अनंत दीक्षित यांच्या निधनाचे वृत्त दुखद आहे']"
      ],
      "metadata": {
        "id": "6wO1dWnC9MO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text[0] = text[0].strip()"
      ],
      "metadata": {
        "id": "KL6sTtvUcLVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text = text.strip()"
      ],
      "metadata": {
        "id": "7DO4c_hlA27v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text =df['tweet'][:10]"
      ],
      "metadata": {
        "id": "IfVPMUMGcIyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i=1\n",
        "# savename = '/content/gdrive/My Drive/dataset/tweets-train_12114_translated_'+str(fin)+'.csv'"
      ],
      "metadata": {
        "id": "1lbuFH_0iqnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# savename"
      ],
      "metadata": {
        "id": "S_pwixpPi4n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "  text =df['tweet'][i*1000:(i+1)*1000]\n",
        "  a2 = indic2en_model.batch_translate(text.to_list(), 'mr', 'en')\n",
        "  df['tweet'][i*1000:(i+1)*1000] = a2\n",
        "  savename = '/content/gdrive/My Drive/dataset/tweets-train_12114_translated_'+str(i)+'.csv'\n",
        "  df.to_csv(savename)\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUmGdIDr_9yk",
        "outputId": "1369f559-dac6-4b41-d5ff-d02bb8c85d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 4340.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =df['tweet'][12000:12114]\n",
        "a2 = indic2en_model.batch_translate(text.to_list(), 'mr', 'en')\n",
        "df['tweet'][12000:12114] = a2\n",
        "savename = '/content/gdrive/My Drive/dataset/tweets-train_12114_translated_fin.csv'\n",
        "df.to_csv(savename)"
      ],
      "metadata": {
        "id": "RQJOL5t0jC_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc"
      ],
      "metadata": {
        "id": "djje78pfjj6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2[0]"
      ],
      "metadata": {
        "id": "oYn9v4zoB76F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'][:1000] = a2"
      ],
      "metadata": {
        "id": "18-ZxjIDLNRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'][7870]"
      ],
      "metadata": {
        "id": "zkNLY2cHLW2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/gdrive/My Drive/img data/tweets-train_pp_img_tweets_translated_punctuation.csv')"
      ],
      "metadata": {
        "id": "l20UHdkHN-qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en2indic_model = Model(expdir='/content/gdrive/MyDrive/translate/en-indic')"
      ],
      "metadata": {
        "id": "le0dZFDEA8wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('/content/gdrive/My Drive/dataset/tweets-train_12114_translated_gpu_fin.csv', sep=',')"
      ],
      "metadata": {
        "id": "K6QzB1MhsR3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2400):\n",
        "  text =df2['tweet'][i*5:(i+1)*5]\n",
        "  a2 = en2indic_model.batch_translate(text.to_list(), 'en', 'mr')\n",
        "  df2['tweet'][i*5:(i+1)*5] = a2\n",
        "  if i%100 == 0:\n",
        "    savename = '/content/gdrive/My Drive/dataset/tweets-train_12114_backtranslated_gpu_'+str(i)+'.csv'\n",
        "    df2.to_csv(savename,index=False)\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "InDyMQ24azyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text =df2['tweet'][12000:12114]\n",
        "a2 = en2indic_model.batch_translate(text.to_list(), 'en', 'mr')\n",
        "df2['tweet'][12000:12114] = a2\n",
        "savename = '/content/gdrive/My Drive/dataset/tweets-train_12114_backtranslated_gpu_fin.csv'\n",
        "df2.to_csv(savename,index=False)"
      ],
      "metadata": {
        "id": "TkVZIBcza-U_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}